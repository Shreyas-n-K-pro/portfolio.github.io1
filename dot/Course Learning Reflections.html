<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Course Learning Reflections</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      line-height: 1.6;
      margin: 20px;
      background-color: #f9f9f9;
      color: #333;
    }
    h3, h4, h5 {
      color: #2c3e50;
    }
    h3 {
      font-size: 24px;
      margin-bottom: 10px;
      border-bottom: 2px solid #3498db;
      padding-bottom: 5px;
    }
    h4 {
      font-size: 20px;
      margin-top: 20px;
    }
    h5 {
      font-size: 18px;
      margin-top: 10px;
      margin-bottom: 5px;
    }
    p {
      margin: 5px 0;
    }
    ul {
      margin-left: 20px;
    }
    ul li {
      margin: 5px 0;
      list-style-type: disc;
    }
    .container {
      max-width: 800px;
      margin: 0 auto;
      background: #ffffff;
      padding: 20px;
      border-radius: 8px;
      box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
    }
  </style>
</head>
<body>
  <div class="container">
    <h3>Course Learning Reflections</h3>
    <h4>&bull; &nbsp;What are the kinds of problems we see in the nature? (iteration, recursion, backtracking)</h4>
    <h5>1. Iteration Problems</h5>
    <h5>Examples in Nature</h5>
    <p>Iteration means repeating steps in a loop until the job is done.</p>
    <ul>
      <li>Think of the sun rising and setting every day—it’s a repeating cycle.</li>
      <li>Counting the rings on a tree to know its age—each ring is added one at a time over the years.</li>
    </ul>
    
    <h5>Examples in Coding</h5>
    <ul>
      <li>Going through a list to find the largest number.</li>
      <li>Adding all the numbers in a group (like calculating your total grocery bill).</li>
    </ul>

    <h4>2. Recursion Problems</h4>
    <h5>Examples in Nature</h5>
    <p>Recursion is when a problem solves itself in smaller steps until it’s complete.</p>
    <ul>
      <li>Imagine a tree: A branch splits into smaller branches, which split into even smaller branches.</li>
      <li>Think of how you fold a piece of paper in half repeatedly—it’s the same process over and over.</li>
    </ul>
    
    <h5>Examples in Coding</h5>
    <ul>
      <li>Calculating factorials (e.g., 5! = 5 × 4 × 3 × 2 × 1).</li>
      <li>Finding your way through a family tree or exploring nested folders on your computer.</li>
    </ul>

    <h4>3. Backtracking Problems</h4>
    <h5>Examples in Nature</h5>
    <p>Backtracking is like trial and error: you try a path, and if it doesn’t work, you go back and try another one.</p>
    <ul>
      <li>Picture an ant trying to find food—it explores one path, and if it’s blocked, it turns around and tries a different way.</li>
      <li>Solving a maze: If one route doesn’t work, you go back and try a new direction.</li>
    </ul>
    
    <h5>Examples in Coding</h5>
    <ul>
      <li>Solving puzzles like Sudoku.</li>
      <li>Finding all possible combinations, like arranging letters to form words.</li>
      <li>Figuring out the shortest route on a map.</li>
    </ul>

    <h4>Space and Time Efficiency</h4>
    <p>Time Efficiency is about how fast an algorithm runs. Imagine you’re baking a cake—time efficiency is how quickly you can finish baking.</p>
    <p>Space Efficiency is about how much memory or storage an algorithm uses while running. It’s like how many bowls or tools you need to bake that cake. The fewer, the better.</p>
    
    <h5>Why Are They Important?</h5>
    <ul>
      <li><strong>Save Time:</strong> Faster algorithms mean less waiting.</li>
      <li><strong>Save Memory:</strong> Efficient algorithms don’t use too much computer memory, so your device won’t slow down or crash.</li>
      <li><strong>Handle Bigger Problems:</strong> Efficient algorithms can process large amounts of data without issues.</li>
      <li><strong>Better User Experience:</strong> Nobody likes apps or websites that are slow and laggy.</li>
    </ul>

    <h5>Types of Problems</h5>
    <ul>
      <li><strong>Easy Problems (P):</strong> Problems that computers can solve quickly. For example, sorting a list of names or finding the shortest path on a map.</li>
      <li><strong>Tricky Problems (NP):</strong> Harder to solve but easy to check, like solving a jigsaw puzzle.</li>
      <li><strong>Super Tricky Problems (NP-Complete):</strong> The hardest puzzles. If we figure out a fast way to solve one of them, we can solve many other tricky problems just as fast.</li>
      <li><strong>Impossible Problems (NP-Hard):</strong> Problems so tough that no one knows how to solve them efficiently—or even check the answer easily in some cases.</li>
    </ul>
    <h4>&bull; &nbsp;What is space and time efficiency? Why are they important? Explain the different class of problems and orders of growth</h4>
    <h5>Orders of Growth (How Algorithms Grow as Input Increases)</h5>
    <ul>
      <li><strong>O(1) – Constant Time:</strong> No matter the size, it always takes the same time. Example: Picking the first book from a pile.</li>
      <li><strong>O(log n) – Logarithmic Time:</strong> Grows slowly as input increases. Example: Finding a name in a phone book (binary search).</li>
      <li><strong>O(n) – Linear Time:</strong> Time grows directly with input size. Example: Reading all the books in a stack one by one.</li>
      <li><strong>O(n log n) – Linearithmic Time:</strong> Grows a bit faster, often seen in efficient sorting methods. Example: Sorting your books by size.</li>
      <li><strong>O(n²) – Quadratic Time:</strong> Time grows really fast, usually when there are nested loops. Example: Comparing every book with every other book.</li>
      <li><strong>O(2ⁿ) – Exponential Time:</strong> Time doubles with each new piece of data. Example: Trying every possible combination of books to find the best arrangement.</li>
      <li><strong>O(n!) – Factorial Time:</strong> Time explodes! Example: Arranging 10 books in every possible order (10! = 3,628,800 ways).</li>
    </ul>

    <h4>&bull; &nbsp;The hierarchical data and how different tree data structures solve and optimize over the problem scenarios (tree, bst, avl, 2-3, red-black, heap, trie)</h4>
    <h5>1. Basic Tree (Unbalanced Tree)</h5>
    <p><strong>Structure:</strong> A basic tree has nodes connected in a parent-child relationship but doesn't impose any ordering or balancing rules.</p>
    <p><strong>Problem:</strong> Search operations can be inefficient if the tree becomes unbalanced, potentially degrading to a linear structure (like a linked list).</p>
    <strong>Optimization:</strong> This is the most straightforward structure but doesn't optimize performance for large datasets.</p>

    <h5>2. Binary Search Tree (BST)</h5>
    <p><strong>Structure:</strong> A BST is a type of tree where each node has at most two children. For any given node, all nodes in the left subtree have smaller values, and all nodes in the right subtree have larger values.</p>
    <p><strong>Problem:</strong> If the tree becomes unbalanced (like a linked list), operations like search, insertion, and deletion can degrade to O(n) time complexity.</p>
    <p><strong>Optimization:</strong> Ideal for ordered data, allowing efficient searching, insertion, and deletion in O(log n) time for balanced trees.</p>

    <h5>3. AVL Tree (Adelson-Velsky and Landis Tree)</h5>
    <p><strong>Structure:</strong> An AVL tree is a self-balancing binary search tree where the difference between the heights of the left and right subtrees of every node is at most one.</p>
    <p><strong>Problem:</strong> Balancing the tree during insertions and deletions adds overhead.</p>
    <p><strong>Optimization:</strong> Ensures O(log n) time complexity for search, insert, and delete operations by maintaining balance at all times.</p>

    <h5>4. 2-3 Tree</h5>
    <p><strong>Structure:</strong> A 2-3 tree is a balanced search tree where each node can have 2 or 3 children and 1 or 2 keys.</p>
    <p><strong>Problem:</strong> Less efficient for memory usage than other trees, especially when data is sparse.</p>
    <p><strong>Optimization:</strong> It’s a balanced tree that ensures efficient search operations with a guaranteed O(log n) time complexity.</p>

    <h5>5. Red-Black Tree</h5>
    <p><strong>Structure:</strong> A red-black tree is a self-balancing binary search tree with an additional property that each node is either red or black, helping to maintain balance.</p>
    <p><strong>Problem:</strong> Insertion and deletion may require rebalancing.</p>
    <p><strong>Optimization:</strong> Red-black trees are balanced with O(log n) time complexity for insertions, deletions, and lookups.</p>

    <h5>6. Heap</h5>
    <p><strong>Structure:</strong> A heap is a special tree-based structure where the parent node is ordered in a specific way (max-heap or min-heap).</p>
    <p><strong>Problem:</strong> Heaps are not suited for searching arbitrary elements.</p>
    <p><strong>Optimization:</strong> Efficient for priority queue operations, like retrieving the maximum or minimum element in O(1) time and inserting or deleting elements in O(log n) time.</p>

    <h5>7. Trie</h5>
    <p><strong>Structure:</strong> A trie is a tree-like data structure used for storing a dynamic set of strings, where each node represents a character of the string.</p>
    <p><strong>Problem:</strong> Memory usage can be high when there are many nodes for common prefixes.</p>
    <p><strong>Optimization:</strong> Ideal for tasks like searching for a word or prefix, providing O(m) time complexity, where m is the length of the word being searched.</p>
  </div>
</body>
</html>

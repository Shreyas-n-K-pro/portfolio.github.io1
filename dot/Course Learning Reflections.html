<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Course Learning Reflections</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      line-height: 1.6;
      margin: 20px;
      background-color: #f9f9f9;
      color: #333;
    }
    h3, h4, h5 {
      color: #2c3e50;
    }
    h3 {
      font-size: 24px;
      margin-bottom: 10px;
      border-bottom: 2px solid #3498db;
      padding-bottom: 5px;
    }
    h4 {
      font-size: 20px;
      margin-top: 20px;
    }
    h5 {
      font-size: 18px;
      margin-top: 10px;
      margin-bottom: 5px;
    }
    p {
      margin: 5px 0;
    }
    ul {
      margin-left: 20px;
    }
    ul li {
      margin: 5px 0;
      list-style-type: disc;
    }
    .container {
      max-width: 800px;
      margin: 0 auto;
      background: #ffffff;
      padding: 20px;
      border-radius: 8px;
      box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
    }
  </style>
</head>
<body>
  <div class="container">
    <h3>Course Learning Reflections</h3>

    <h4>1. Iteration Problems</h4>
    <h5>Examples in Nature</h5>
    <p>Iteration means repeating steps in a loop until the job is done.</p>
    <ul>
      <li>Think of the sun rising and setting every day—it’s a repeating cycle.</li>
      <li>Counting the rings on a tree to know its age—each ring is added one at a time over the years.</li>
    </ul>
    
    <h5>Examples in Coding</h5>
    <ul>
      <li>Going through a list to find the largest number.</li>
      <li>Adding all the numbers in a group (like calculating your total grocery bill).</li>
    </ul>

    <h4>2. Recursion Problems</h4>
    <h5>Examples in Nature</h5>
    <p>Recursion is when a problem solves itself in smaller steps until it’s complete.</p>
    <ul>
      <li>Imagine a tree: A branch splits into smaller branches, which split into even smaller branches.</li>
      <li>Think of how you fold a piece of paper in half repeatedly—it’s the same process over and over.</li>
    </ul>
    
    <h5>Examples in Coding</h5>
    <ul>
      <li>Calculating factorials (e.g., 5! = 5 × 4 × 3 × 2 × 1).</li>
      <li>Finding your way through a family tree or exploring nested folders on your computer.</li>
    </ul>

    <h4>3. Backtracking Problems</h4>
    <h5>Examples in Nature</h5>
    <p>Backtracking is like trial and error: you try a path, and if it doesn’t work, you go back and try another one.</p>
    <ul>
      <li>Picture an ant trying to find food—it explores one path, and if it’s blocked, it turns around and tries a different way.</li>
      <li>Solving a maze: If one route doesn’t work, you go back and try a new direction.</li>
    </ul>
    
    <h5>Examples in Coding</h5>
    <ul>
      <li>Solving puzzles like Sudoku.</li>
      <li>Finding all possible combinations, like arranging letters to form words.</li>
      <li>Figuring out the shortest route on a map.</li>
    </ul>

    <h4>Space and Time Efficiency</h4>
    <p>Time Efficiency is about how fast an algorithm runs. Imagine you’re baking a cake—time efficiency is how quickly you can finish baking.</p>
    <p>Space Efficiency is about how much memory or storage an algorithm uses while running. It’s like how many bowls or tools you need to bake that cake. The fewer, the better.</p>
    
    <h5>Why Are They Important?</h5>
    <ul>
      <li><strong>Save Time:</strong> Faster algorithms mean less waiting.</li>
      <li><strong>Save Memory:</strong> Efficient algorithms don’t use too much computer memory, so your device won’t slow down or crash.</li>
      <li><strong>Handle Bigger Problems:</strong> Efficient algorithms can process large amounts of data without issues.</li>
      <li><strong>Better User Experience:</strong> Nobody likes apps or websites that are slow and laggy.</li>
    </ul>

    <h5>Types of Problems</h5>
    <ul>
      <li><strong>Easy Problems (P):</strong> Problems that computers can solve quickly. For example, sorting a list of names or finding the shortest path on a map.</li>
      <li><strong>Tricky Problems (NP):</strong> Harder to solve but easy to check, like solving a jigsaw puzzle.</li>
      <li><strong>Super Tricky Problems (NP-Complete):</strong> The hardest puzzles. If we figure out a fast way to solve one of them, we can solve many other tricky problems just as fast.</li>
      <li><strong>Impossible Problems (NP-Hard):</strong> Problems so tough that no one knows how to solve them efficiently—or even check the answer easily in some cases.</li>
    </ul>

    <h5>Orders of Growth (How Algorithms Grow as Input Increases)</h5>
    <ul>
      <li><strong>O(1) – Constant Time:</strong> No matter the size, it always takes the same time. Example: Picking the first book from a pile.</li>
      <li><strong>O(log n) – Logarithmic Time:</strong> Grows slowly as input increases. Example: Finding a name in a phone book (binary search).</li>
      <li><strong>O(n) – Linear Time:</strong> Time grows directly with input size. Example: Reading all the books in a stack one by one.</li>
      <li><strong>O(n log n) – Linearithmic Time:</strong> Grows a bit faster, often seen in efficient sorting methods. Example: Sorting your books by size.</li>
      <li><strong>O(n²) – Quadratic Time:</strong> Time grows really fast, usually when there are nested loops. Example: Comparing every book with every other book.</li>
      <li><strong>O(2ⁿ) – Exponential Time:</strong> Time doubles with each new piece of data. Example: Trying every possible combination of books to find the best arrangement.</li>
      <li><strong>O(n!) – Factorial Time:</strong> Time explodes! Example: Arranging 10 books in every possible order (10! = 3,628,800 ways).</li>
    </ul>
  </div>
</body>
</html>
